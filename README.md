# üß† Extra√ß√£o, Chunking e Indexa√ß√£o Inteligente de Documentos PDF/DOCX

## Vis√£o Geral

Pipeline completo para processamento de documentos PDF, DOCX e imagens, incluindo:

- **Extra√ß√£o de Texto:** Diversas estrat√©gias (PyPDFLoader, PDFMinerLoader, PDFMiner Low-Level, Unstructured, OCR para PDF, OCR para Imagens, PDFPlumber, PyMuPDF4LLM)
- **Chunking Inteligente:** Filtragem de par√°grafos, reconhecimento de headings, agrupamento, sliding window com overlap configur√°vel e fallback para par√°grafos longos
- **Embeddings Vetoriais:** Suporte a m√∫ltiplos modelos (Ollama, Serafim-PT-IR, MPNet, MiniLM) com padding e truncation autom√°ticos
- **Indexa√ß√£o & Busca H√≠brida (RAG):** PostgreSQL + pgvector usando tabelas dedicadas por dimens√£o
- **Re-ranking:** Cross-Encoder (ms-marco) para maior precis√£o
- **Monitoramento:** Prometheus (lat√™ncia, contagem de buscas, tamanho dos resultados)
- **CLI Interativo:** Sele√ß√£o de estrat√©gia, modelo, dimens√£o **e dispositivo (cpu/gpu/auto)**, modo verboso, processamento em lote com barra de progresso e estat√≠sticas em tempo real
 - **Organiza√ß√£o:** Arquivos processados s√£o movidos para a subpasta `processado`,
   que √© ignorada em execu√ß√µes futuras

---

## Funcionalidades

### 1. Extra√ß√£o de Texto

- Detec√ß√£o autom√°tica de PDFs criptografados com fallback para OCR (`pytesseract` + `pdf2image`)
- Suporte a OCR direto em imagens (PNG, JPG, JPEG, TIFF (.tif) e BMP (.bmp))

**Estrat√©gias Dispon√≠veis:**
- PyPDFLoader (LangChain)
- PDFMinerLoader (LangChain)
- PDFMiner Low-Level (pdfminer.six)
- Unstructured (.docx)
- OCR Hybrid para PDF (pytesseract)
- A vari√°vel `TESSERACT_CONFIG` permite ajustar par√¢metros do Tesseract
- ImageOCR (PIL + pytesseract)
- PDFPlumber
- PyMuPDF4LLM (Markdown)

### 2. Chunking Inteligente

- Filtragem de par√°grafos: remove sum√°rios, √≠ndices e trechos muito curtos (< 50 caracteres)
- Reconhecimento de headings: se√ß√µes baseadas em padr√µes num√©ricos (ex: 1.2 T√≠tulo)
- Agrupamento de par√°grafos at√© `max_tokens`
- Subdivis√£o de par√°grafos longos: sliding window com overlap (`SLIDING_WINDOW_OVERLAP_RATIO`)
- Fallback `TokenTextSplitter` para casos excepcionais
- Expans√£o de Query: sin√¥nimos via WordNet em `metadata.__query_expanded`

### 3. Modelos de Embedding & Dimens√µes

| Op√ß√£o | Modelo                                                                 | Dimens√£o |
|-------|------------------------------------------------------------------------|----------|
| 1     | mxbai-embed-large (Ollama API)                                         | 1024     |
| 2     | PORTULAN/serafim-900m-portuguese-pt-sentence-encoder-ir (pt-BR IR)     | 1536     |
| 3     | sentence-transformers/all-mpnet-base-v2 (English MPNet)                | 768      |
| 4     | sentence-transformers/all-MiniLM-L6-v2 (MiniLM L6 multilingual)        | 384      |
| 5     | sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2 (MiniLM L12 multilingual) | 384      |

Todos os modelos e dimens√µes s√£o configur√°veis no arquivo `.env`.

### 4. Indexa√ß√£o e Busca

- **Banco:** PostgreSQL + extens√£o pgvector

**Tabelas por dimens√£o:**
- `public.documents_384`
- `public.documents_768`
- `public.documents_1024`
- `public.documents_1536`

**Fun√ß√µes Unificadas:**
- `public.match_documents_hybrid(query_embedding, query_text, ...)`
- `public.match_documents_precise(query_embedding, query_text, ...)`

**√çndices e Extens√µes:**
- `vector` (pgvector)
- HNSW / IVFFlat para busca vetorial em cada tabela
- GIN em `tsv_full` e `metadata`
- GIN trigram (`gin_trgm_ops`) em `title`, `author`, `type`, `__parent`

-### 5. Re-ranking & M√©tricas

- **Cross-Encoder:** `cross-encoder/ms-marco-MiniLM-L-6-v2` para reranking de pares (query, conte√∫do) com cache por dispositivo
- **Prometheus:** iniciar com `start_metrics_server()` para expor m√©tricas em `localhost:8000/metrics`
    - `rag_query_executions_total`
    - `rag_query_duration_seconds`
    - `rag_last_query_result_count`

### 6. CLI Interativo & Estat√≠sticas

**Menu Principal:**
- Selecionar Estrat√©gia de Extra√ß√£o
- Selecionar Embedding Model
- Selecionar Dimens√£o
- Selecionar Dispositivo (CPU/GPU/Auto)
- Processar Arquivo / Pasta (inclui imagens)
 - Mover arquivos conclu√≠dos para a subpasta `processado` (essa pasta √© ignorada ao processar pastas)
- Sair

**Flags:**
- `--verbose`: logs detalhados

**Progresso:** `tqdm` com `set_postfix` para processados/erros

**Resumo Final:** totais de processados, erros e tempo total

---

## Requisitos de Sistema

- Testado em Debian 12 / Ubuntu 22.04
- Python 3.8+

---

## Depend√™ncias do Sistema

```bash
sudo apt update
sudo apt install -y \
        poppler-utils \
        mupdf-tools \
        ghostscript \
        qpdf \
        tesseract-ocr \
        tesseract-ocr-eng tesseract-ocr-por \
        libpoppler-cpp-dev pkg-config \
        imagemagick \
        libmagic1 \
        fontconfig
```

Para `pdftotext` Python:  
`pip install pdftotext` ap√≥s `libpoppler-cpp-dev pkg-config`.

---

## Instala√ß√£o

Clone o reposit√≥rio:

```bash
git clone https://github.com/seu_usuario/seu_projeto.git
cd seu_projeto
```

Crie e ative um virtualenv:

```bash
python3 -m venv .venv
source .venv/bin/activate
```

Instale depend√™ncias Python:

```bash
pip install -r requirements.txt
```

---

## Exemplo de `.env`

```env
# NVD API Key (para incremental)
NVD_API_KEY=98dbb4f5-7540-4ca1-ae81-ffabf4b076b6

# PostgreSQL Connection
PG_HOST=172.16.187.133
PG_PORT=5432
PG_USER=vector_store
PG_PASSWORD=sua_senha
PG_DATABASE=vector_store

# Modelos & Dimens√µes
OLLAMA_EMBEDDING_MODEL=mixedbread-ai/mxbai-embed-large-v1
DIM_MXBAI=1024
SERAFIM_EMBEDDING_MODEL=PORTULAN/serafim-900m-portuguese-pt-sentence-encoder-ir
DIM_SERAFIM=1536
MINILM_L6_V2=sentence-transformers/all-MiniLM-L6-v2
DIM_MINILM_L6=384
MINILM_L12_V2=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
DIM_MINIL12=384
MPNET_EMBEDDING_MODEL=sentence-transformers/all-mpnet-base-v2
DIM_MPNET=768

# OCR
OCR_THRESHOLD=100
OCR_LANGUAGES=eng+por
TESSERACT_CONFIG=""
PDF2IMAGE_TIMEOUT=600

# Chunking
CHUNK_SIZE=1024
CHUNK_OVERLAP=700
SLIDING_WINDOW_OVERLAP_RATIO=0.25
MAX_SEQ_LENGTH=128
SEPARATORS="\n\n|\n|\.|!|\?|;"

# CSV locais (NVD)
CSV_FULL=vulnerabilidades_full.csv
CSV_INCR=vulnerabilidades_incrementais.csv
```

---

## Prepara√ß√£o do Banco PostgreSQL

Instale extens√µes dentro do banco:

```sql
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS pg_trgm;
```

Execute o DDL completo para criar tabelas, dicion√°rios, configura√ß√£o FTS, triggers e √≠ndices conforme as instru√ß√µes.

---

## Executando o CLI

```bash
python3 main.py [--verbose]
```

---

## Melhorias e Adapta√ß√µes Recentes

Nas vers√µes anteriores, experimentamos ‚ÄúMorto‚Äù (SIGKILL) ao processar grande quantidade de arquivos, devido a uso excessivo de mem√≥ria GPU e fragmenta√ß√£o de objetos. Para resolver esses problemas, aplicamos as seguintes melhorias:

### 1. Sele√ß√£o de Dispositivo e Cache (`adaptive_chunker.py`)

**Antes:**
```python
device = "cuda" if torch.cuda.is_available() else "cpu"
SentenceTransformer(model_name, device=device)
```
Carregava SBERT na GPU sempre que dispon√≠vel, gerando OOM.

**Agora:**
```python
SentenceTransformer(model_name, device=selected_device)
```
SBERT √© carregado apenas uma vez no dispositivo escolhido (`cpu`, `gpu` ou `auto`), com cache separado por dispositivo.

### 2. Inference sem gradiente e limpeza agressiva (`pg_storage.py`)

- Uso de `torch.no_grad()`: envolve `model.encode(...)` para evitar cria√ß√£o de buffers de gradientes.
- Limpeza de mem√≥ria GPU: chama `torch.cuda.empty_cache()` ap√≥s cada gera√ß√£o de embedding.
- Fallback transparente: tratamento de `RuntimeError` (‚Äúout of memory‚Äù), mas raramente acionado, j√° que SBERT roda em CPU.

### 3. Coleta de Lixo Imediata e Remo√ß√£o de Refer√™ncias Grandes (`main.py`)

Depois de salvar cada documento:
```python
del text
del rec
import gc; gc.collect()
```
Remove explicitamente strings e metadados volumosos e for√ßa coleta de lixo, reduzindo footprint de RAM entre processamentos.

Coleta ao final de cada arquivo no loop de pasta: chama `gc.collect()` dentro do loop para garantir libera√ß√£o de objetos grandes antes de seguir para o pr√≥ximo.

### 4. Ajustes no Processo de `generate_embedding`

- **Padding/Truncation Autom√°tico:** ajusta o vetor resultante (`vec`) para ter exatamente a dimens√£o esperada, adicionando zeros ou truncando excedentes.
- **Tratamento de Exce√ß√µes Robusto:** em caso de qualquer falha na gera√ß√£o de embedding, retorna vetor de zeros ‚Äî evitando quebra total do pipeline.

---

## Changelog de Exemplo

```yaml
feat: otimiza√ß√µes de mem√≥ria e estabilidade no processamento em lote
- Carregar SBERT no dispositivo escolhido (CPU/GPU) com cache por dispositivo
- Adicionar torch.no_grad() no encode para n√£o manter gradientes
- Incluir torch.cuda.empty_cache() ap√≥s cada embedding
- Chamar del text, del rec e gc.collect() em main.py para liberar mem√≥ria RAM
- Ajustar generate_embedding para padding/truncation e fallback robusto
- Atualizar README com detalhes das melhorias aplicadas
```
